{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n"
      ],
      "metadata": {
        "id": "Gm3fd-699p_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "vDWRJTVb9Usy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "HW49KJXR9tXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('/content/train.csv')\n",
        "data_test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "VtZ1we-L9V6w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separate features (X) and target variable (y)\n"
      ],
      "metadata": {
        "id": "mhDlNgX-9xVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data_train.drop('Class', axis=1)\n",
        "y_train = data_train['Class']"
      ],
      "metadata": {
        "id": "elzdO3Sq9XKF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = data_test.drop('Class', axis=1)\n",
        "y_test = data_test['Class']"
      ],
      "metadata": {
        "id": "Dg1-18Ev9aQ3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Logistic Regression without Handling Imbalance\n"
      ],
      "metadata": {
        "id": "V0ji24Q090IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression without Handling Imbalance:\")\n",
        "logreg_model = LogisticRegression(random_state=42)\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg_model.predict(X_train)\n",
        "print(\"Confusion Matrix (Train):\\n\", confusion_matrix(y_train, y_pred))\n",
        "print(\"Classification Report (Train):\\n\", classification_report(y_train, y_pred))\n",
        "\n",
        "y_pred_test = logreg_model.predict(X_test)\n",
        "print(\"Confusion Matrix (Test):\\n\", confusion_matrix(y_test, y_pred_test))\n",
        "print(\"Classification Report (Test):\\n\", classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3mt6dbB9d9k",
        "outputId": "a40d2876-e0e4-4e3b-8951-36ed06404d1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression without Handling Imbalance:\n",
            "Confusion Matrix (Train):\n",
            " [[2090  140]\n",
            " [ 132 1318]]\n",
            "Classification Report (Train):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      2230\n",
            "           1       0.90      0.91      0.91      1450\n",
            "\n",
            "    accuracy                           0.93      3680\n",
            "   macro avg       0.92      0.92      0.92      3680\n",
            "weighted avg       0.93      0.93      0.93      3680\n",
            "\n",
            "Confusion Matrix (Test):\n",
            " [[524  34]\n",
            " [ 43 320]]\n",
            "Classification Report (Test):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       558\n",
            "           1       0.90      0.88      0.89       363\n",
            "\n",
            "    accuracy                           0.92       921\n",
            "   macro avg       0.91      0.91      0.91       921\n",
            "weighted avg       0.92      0.92      0.92       921\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Logistic Regression with Oversampling\n"
      ],
      "metadata": {
        "id": "dPpzsdN_92Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLogistic Regression with Oversampling:\")\n",
        "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "X_resampled_over, y_resampled_over = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "logreg_model_over = LogisticRegression(random_state=42)\n",
        "logreg_model_over.fit(X_resampled_over, y_resampled_over)\n",
        "\n",
        "y_pred_over = logreg_model_over.predict(X_resampled_over)\n",
        "print(\"Confusion Matrix (Train with Oversampling):\\n\", confusion_matrix(y_resampled_over, y_pred_over))\n",
        "print(\"Classification Report (Train with Oversampling):\\n\", classification_report(y_resampled_over, y_pred_over))\n",
        "\n",
        "y_pred_over_test = logreg_model_over.predict(X_test)\n",
        "print(\"Confusion Matrix (Test with Oversampling):\\n\", confusion_matrix(y_test, y_pred_over_test))\n",
        "print(\"Classification Report (Test with Oversampling):\\n\", classification_report(y_test, y_pred_over_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co3x4pSy9hyZ",
        "outputId": "17109297-e79a-454a-f2c3-3bf9f46b3348"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression with Oversampling:\n",
            "Confusion Matrix (Train with Oversampling):\n",
            " [[2058  172]\n",
            " [ 167 2063]]\n",
            "Classification Report (Train with Oversampling):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92      2230\n",
            "           1       0.92      0.93      0.92      2230\n",
            "\n",
            "    accuracy                           0.92      4460\n",
            "   macro avg       0.92      0.92      0.92      4460\n",
            "weighted avg       0.92      0.92      0.92      4460\n",
            "\n",
            "Confusion Matrix (Test with Oversampling):\n",
            " [[515  43]\n",
            " [ 38 325]]\n",
            "Classification Report (Test with Oversampling):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.93       558\n",
            "           1       0.88      0.90      0.89       363\n",
            "\n",
            "    accuracy                           0.91       921\n",
            "   macro avg       0.91      0.91      0.91       921\n",
            "weighted avg       0.91      0.91      0.91       921\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Logistic Regression with Undersampling\n"
      ],
      "metadata": {
        "id": "FDAv8iAP93hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLogistic Regression with Undersampling:\")\n",
        "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "X_resampled_under, y_resampled_under = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "logreg_model_under = LogisticRegression(random_state=42)\n",
        "logreg_model_under.fit(X_resampled_under, y_resampled_under)\n",
        "\n",
        "y_pred_under = logreg_model_under.predict(X_resampled_under)\n",
        "print(\"Confusion Matrix (Train with Undersampling):\\n\", confusion_matrix(y_resampled_under, y_pred_under))\n",
        "print(\"Classification Report (Train with Undersampling):\\n\", classification_report(y_resampled_under, y_pred_under))\n",
        "\n",
        "y_pred_under_test = logreg_model_under.predict(X_test)\n",
        "print(\"Confusion Matrix (Test with Undersampling):\\n\", confusion_matrix(y_test, y_pred_under_test))\n",
        "print(\"Classification Report (Test with Undersampling):\\n\", classification_report(y_test, y_pred_under_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2jkCYF89kdO",
        "outputId": "aaa19c1c-dcbd-4ade-e85f-e8a1596d65ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression with Undersampling:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Train with Undersampling):\n",
            " [[1320  130]\n",
            " [ 104 1346]]\n",
            "Classification Report (Train with Undersampling):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      1450\n",
            "           1       0.91      0.93      0.92      1450\n",
            "\n",
            "    accuracy                           0.92      2900\n",
            "   macro avg       0.92      0.92      0.92      2900\n",
            "weighted avg       0.92      0.92      0.92      2900\n",
            "\n",
            "Confusion Matrix (Test with Undersampling):\n",
            " [[517  41]\n",
            " [ 33 330]]\n",
            "Classification Report (Test with Undersampling):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93       558\n",
            "           1       0.89      0.91      0.90       363\n",
            "\n",
            "    accuracy                           0.92       921\n",
            "   macro avg       0.91      0.92      0.92       921\n",
            "weighted avg       0.92      0.92      0.92       921\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Logistic Regression with Weighted Loss Function\n"
      ],
      "metadata": {
        "id": "UwcaAqkx95nb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcyCbK649SlZ",
        "outputId": "cb211338-cc2c-4ffc-ac73-5144372322ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression with Weighted Loss Function:\n",
            "Confusion Matrix (Train with Weighted Loss):\n",
            " [[2059  171]\n",
            " [ 111 1339]]\n",
            "Classification Report (Train with Weighted Loss):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.94      2230\n",
            "           1       0.89      0.92      0.90      1450\n",
            "\n",
            "    accuracy                           0.92      3680\n",
            "   macro avg       0.92      0.92      0.92      3680\n",
            "weighted avg       0.92      0.92      0.92      3680\n",
            "\n",
            "Confusion Matrix (Test with Weighted Loss):\n",
            " [[518  40]\n",
            " [ 37 326]]\n",
            "Classification Report (Test with Weighted Loss):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       558\n",
            "           1       0.89      0.90      0.89       363\n",
            "\n",
            "    accuracy                           0.92       921\n",
            "   macro avg       0.91      0.91      0.91       921\n",
            "weighted avg       0.92      0.92      0.92       921\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nLogistic Regression with Weighted Loss Function:\")\n",
        "class_weights = dict(zip([0, 1], len(y_train) / (2 * y_train.value_counts())))\n",
        "\n",
        "logreg_model_weighted = LogisticRegression(class_weight=class_weights, random_state=42)\n",
        "logreg_model_weighted.fit(X_train, y_train)\n",
        "\n",
        "y_pred_weighted = logreg_model_weighted.predict(X_train)\n",
        "print(\"Confusion Matrix (Train with Weighted Loss):\\n\", confusion_matrix(y_train, y_pred_weighted))\n",
        "print(\"Classification Report (Train with Weighted Loss):\\n\", classification_report(y_train, y_pred_weighted))\n",
        "\n",
        "y_pred_weighted_test = logreg_model_weighted.predict(X_test)\n",
        "print(\"Confusion Matrix (Test with Weighted Loss):\\n\", confusion_matrix(y_test, y_pred_weighted_test))\n",
        "print(\"Classification Report (Test with Weighted Loss):\\n\", classification_report(y_test, y_pred_weighted_test))\n"
      ]
    }
  ]
}